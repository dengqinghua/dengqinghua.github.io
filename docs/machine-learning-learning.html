<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>机器学习</title>

  <!-- Begin Jekyll SEO tag v2.6.1 -->
<meta name="generator" content="Jekyll v3.8.7" />
<meta property="og:title" content="机器学习" />
<meta name="author" content="dengqinghua" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="机器学习的思考故事" />
<meta property="og:description" content="机器学习的思考故事" />
<link rel="canonical" href="https://dengqinghua.github.io/machine-learning-learning.html" />
<meta property="og:url" content="https://dengqinghua.github.io/machine-learning-learning.html" />
<meta property="og:site_name" content="Dengqinghua.42" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-04T00:00:00+08:00" />
<script type="application/ld+json">
{"headline":"机器学习","dateModified":"2022-01-04T00:00:00+08:00","datePublished":"2022-01-04T00:00:00+08:00","url":"https://dengqinghua.github.io/machine-learning-learning.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://dengqinghua.github.io/machine-learning-learning.html"},"author":{"@type":"Person","name":"dengqinghua"},"description":"机器学习的思考故事","@type":"BlogPosting","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <link type="application/atom+xml" rel="alternate" href="https://dengqinghua.github.io/feed.xml" title="Dengqinghua.42" />

  <link rel="shortcut icon" type="image/x-icon" href="/logo.png" />
  <link rel="stylesheet" href="/assets/css/main.css" />
  <link rel="stylesheet" href="/assets/css/zoom.css" />
  <link rel="stylesheet" href="/assets/css/gitalk.css" />
  <link rel="stylesheet" href="/assets/css/syntax.css" />
  <script src="assets/js/mermaid.min.js"></script>
  <script src="assets/js/jquery.min.js"></script>
  <script src="assets/js/zoom.min.js"></script>
  <script src="assets/js/zoom_init.js"></script>
  <script src="assets/js/mermaid_config.js"></script>
  <script src="assets/js/gitalk.min.js"></script>
  <script src="assets/js/gitalk_init.js"></script>
  <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <script src="assets/js/mathjax_init.js"></script>
</head>
<body a="light">
    <main class="page-content" aria-label="Content">
      <div class="w">
        <a href="/">..</a>

<article>
  <p class="post-meta">
    <time datetime="2022-01-04 00:00:00 +0800">2022-01-04</time>
  </p>
  
  <h1>机器学习</h1>

  <h2 id="机器学习的思考故事">机器学习的思考故事</h2>

<h2 id="吴恩达">吴恩达</h2>
<h3 id="machine-learning">Machine Learning</h3>
<h4 id="week1">Week1</h4>
<blockquote>
  <ol>
    <li>学习算法，模拟人类大脑的学习方式</li>
    <li>Machine Learning defined by Arthur Samuel(1959), ability to learn without explictly programmed</li>
    <li>E, T, P</li>
  </ol>
</blockquote>

<ul>
  <li>Supervised Learning
    <ul>
      <li>给出现有的结果集(Right Answers for each example)，去推导因果关系</li>
      <li>Regression Problem, 回归问题, 预测的是 连续的数据</li>
      <li>Classification Problem, 分类问题，预测的是 有限的取值</li>
      <li>Infinite number of features, 无限的特征和属性</li>
    </ul>
  </li>
  <li>UnSupervised Learning
    <ul>
      <li>No labels</li>
      <li>clusters，聚类</li>
    </ul>
  </li>
  <li>工具: octave</li>
  <li>鸡尾酒会效应(cocktail-party-effect), 人们可以在嘈杂的环境进行交谈，忽略掉背景噪声而听到对方的谈话。属于 图形-背景现象 的听觉版本</li>
</ul>

<p>线性代数算法</p>

<ul>
  <li>Training Set</li>
  <li>m: numbers of training examples</li>
  <li>x’s = input / features</li>
  <li>y’s = output / target variable</li>
  <li>
<script type="math/tex">(x, y)</script> training example</li>
  <li>
<script type="math/tex">(x^{(i)}, y^{(i)})</script> case of i, i 为 index</li>
  <li>h hypothesis, 假设 <script type="math/tex">y = h(x)</script>
</li>
  <li>linare regression with one variable <script type="math/tex">h_\theta = \theta_0 + \theta_1 x</script>
</li>
  <li>univariate linear regression 单变量线性回归</li>
  <li>目标, 找到最小值: <script type="math/tex">minimize_{\theta_0\theta_1} {1 \over2m} \sum_{i=0}^m(h_\theta(x^{(i)}) - y^{(i)})^2</script>
</li>
  <li>Cost Function 定义为 <script type="math/tex">J(\theta_0, \theta_1) = {1 \over2m} \sum_{i=0}^m(\hat y_i - y^{(i)})^2 = {1 \over2m} \sum_{i=0}^m(h_\theta(x^{(i)}) - y^{(i)})^2</script>
</li>
  <li>目标: <script type="math/tex">minimize_{\theta_0\theta_1} J(\theta_0, \theta_1)</script> 为平方差代价函数</li>
  <li>目标: <script type="math/tex">J(\theta_0, \theta_1)</script> 导数为 0 的那个 <script type="math/tex">\theta_1</script> 的值</li>
</ul>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Hypothesis(假设)</th>
      <th style="text-align: center">Paramemters(参数)</th>
      <th style="text-align: center">CostFunction</th>
      <th style="text-align: center">Goal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><script type="math/tex">h_\theta = \theta_0 + \theta_1 x</script></td>
      <td style="text-align: center"><script type="math/tex">\theta_0, \theta_1</script></td>
      <td style="text-align: center"><script type="math/tex">J(\theta_0, \theta_1) = {1 \over2m} \sum_{i=0}^m(h_\theta(x^{(i)}) - y^{(i)})^2</script></td>
      <td style="text-align: center"><script type="math/tex">minimize_{\theta_0\theta_1} J(\theta_0, \theta_1)</script></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>contour plot, 画图的软件, 见 <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/contour.htm" target="_blank" rel="noopener noreferrer">这里</a> 和 <a href="https://plotly.com/javascript/contour-plots/" target="_blank" rel="noopener noreferrer">JS 版本</a>
</li>
</ul>

<p>梯度下降算法 Gradient Descent</p>

<p>每次寻找对应的 <script type="math/tex">\theta_0, \theta_1</script>，使得下面的值越来越小</p>

<script type="math/tex; mode=display">J(\theta_0, \theta_1)</script>

<p>步骤:</p>

<script type="math/tex; mode=display">\text{repeat untile convergence} \\
\\ \theta_j := \theta_j - \alpha \frac{\partial}{\partial \theta_j} {J(\theta_0, \theta_1)},\text{ for (j=0 and j=1)}</script>

<ul>
  <li>
<script type="math/tex">\alpha</script> 为 learning rate，越大代表下降越快。</li>
  <li>
    <p>需要同时更新 <script type="math/tex">\theta_0, \theta_1</script> 的值</p>

    <table>
      <tbody>
        <tr>
          <td><script type="math/tex">temp0 := \theta_0 - \alpha \frac{\partial}{\partial \theta_0} {J(\theta_0, \theta_1)}</script></td>
        </tr>
        <tr>
          <td><script type="math/tex">temp1 := \theta_1 - \alpha \frac{\partial}{\partial \theta_1} {J(\theta_0, \theta_1)}</script></td>
        </tr>
        <tr>
          <td><script type="math/tex">\theta_0 := temp0</script></td>
        </tr>
        <tr>
          <td><script type="math/tex">\theta_1 := temp1</script></td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<p><img src="assets/images/gradient-descent.png" alt="gradient-descent"></p>

<ul>
  <li>通过斜率的变化，来动态调整参数的值，使得达到收敛(converge)的点, 也就是图中的最低点的位置</li>
  <li>偏离 diverge</li>
  <li>
<script type="math/tex">\alpha</script> 很小，则找到具体的点会比较慢, 过大，则容易错过最优点</li>
  <li>
    <p>根据导数的值的大小，动态地调整 <script type="math/tex">\alpha</script> 的值</p>
  </li>
  <li>convex 凸函数(bowl shaped function)</li>
</ul>

<p>第一个机器学习的算法</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Hypothesis(假设)</th>
      <th style="text-align: center">Paramemters(参数)</th>
      <th style="text-align: center">CostFunction</th>
      <th style="text-align: center">Goal</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><script type="math/tex">h_\theta = \theta_0 + \theta_1 x</script></td>
      <td style="text-align: center"><script type="math/tex">\theta_0, \theta_1</script></td>
      <td style="text-align: center"><script type="math/tex">J(\theta_0, \theta_1) = {1 \over2m} \sum_{i=0}^m(h_\theta(x^{(i)}) - y^{(i)})^2</script></td>
      <td style="text-align: center"><script type="math/tex">minimize_{\theta_0\theta_1} J(\theta_0, \theta_1)</script></td>
    </tr>
  </tbody>
</table>

<ol>
  <li>
    <p>对 CostFunction 求导数</p>

    <script type="math/tex; mode=display">% <![CDATA[
\begin{align}
 \frac{\partial}{\partial \theta_j} J(\theta) &= {1 \over m} \sum_{i=0}^m(h_\theta(x^{(i)}) - y^{(i)}) \\
        &= {1 \over m} \sum_{i=0}^m(h_\theta(x^{(i)}) - y^{(i)}) \\
        &= {1 \over m} \sum_{i=0}^m((\theta_0 + \theta_1 x) - y^{(i)})
 \end{align} %]]></script>
  </li>
  <li>
    <p>将 导数 部分代入到 梯度下降算法中</p>

    <script type="math/tex; mode=display">% <![CDATA[
\begin{align}
 \text{repeat untile convergence...} &\{ \\
 temp0 &:= \theta_0 - {\alpha \over m} \sum_{i=0}^m((\theta_0 + \theta_1 x) - y^{(i)}) \\
 temp1 &:= \theta_1 - {\alpha \over m} \sum_{i=0}^m((\theta_0 + \theta_1 x) - y^{(i)}) \\
 \theta_0 &:= temp0 \\
 \theta_1 &:= temp1 \\
 &\}
 \end{align} \\ %]]></script>
  </li>
</ol>

<h2 id="reference">Reference</h2>
<ul>
  <li><a href="https://aistudio.baidu.com/aistudio/education/group/info/1138" target="_blank" rel="noopener noreferrer">机器学习的思考故事</a></li>
  <li><a href="https://aistudio.baidu.com/aistudio/course/introduce/1297" target="_blank" rel="noopener noreferrer">零基础实践机器学习</a></li>
  <li><a href="https://www.coursera.org/learn/machine-learning/home/welcome" target="_blank" rel="noopener noreferrer">吴恩达在 coursera 的机器学习课程</a></li>
</ul>

</article>

<div id="comment"></div>
<script>
  gitalk.render('comment');
</script>



      </div>
    </main>

    
  </body>
</html>